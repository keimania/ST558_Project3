[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Project 3",
    "section": "",
    "text": "In this project, we analyze the Diabetes Health Indicators Dataset, which is derived from the BRFSS 2015 data.\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Read the data (assuming the file is in the root directory)\ndiabetes &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nprint(head(diabetes))\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1               0      1        1         1    40      1      0\n2               0      0        0         0    25      1      0\n3               0      1        1         1    28      0      0\n4               0      1        0         1    27      0      0\n5               0      1        1         1    24      0      0\n6               0      1        1         1    25      1      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nConvert variables to factors with meaningful levels\n\ndiabetes_clean &lt;- diabetes |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary, levels = c(0, 1), labels = c(\"No Diabetes\", \"Diabetes\")),\n    HighBP = factor(HighBP, levels = c(0, 1), labels = c(\"No High BP\", \"High BP\")),\n    HighChol = factor(HighChol, levels = c(0, 1), labels = c(\"No High Chol\", \"High Chol\")),\n    CholCheck = factor(CholCheck, levels = c(0, 1), labels = c(\"No Check\", \"Check in 5 yrs\")),\n    Smoker = factor(Smoker, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Stroke = factor(Stroke, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    PhysActivity = factor(PhysActivity, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Fruits = factor(Fruits, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Veggies = factor(Veggies, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    AnyHealthcare = factor(AnyHealthcare, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    NoDocbcCost = factor(NoDocbcCost, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    GenHlth = factor(GenHlth, levels = c(1, 2, 3, 4, 5), \n                     labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    DiffWalk = factor(DiffWalk, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Sex = factor(Sex, levels = c(0, 1), labels = c(\"Female\", \"Male\")),\n    Age = factor(Age),\n    Education = factor(Education),\n    Income = factor(Income)\n  )\n\n# Check for missing values\nmissing_count &lt;- sum(is.na(diabetes_clean))\ncat(\"Total missing values in the dataset:\", missing_count, \"\\n\")\n\nTotal missing values in the dataset: 0 \n\n\nSummary and Statistics\n\nsummary(diabetes_clean)\n\n    Diabetes_binary          HighBP               HighChol     \n No Diabetes:218334   No High BP:144851   No High Chol:146089  \n Diabetes   : 35346   High BP   :108829   High Chol   :107591  \n                                                               \n                                                               \n                                                               \n                                                               \n                                                               \n          CholCheck           BMI        Smoker       Stroke      \n No Check      :  9470   Min.   :12.00   No :141257   No :243388  \n Check in 5 yrs:244210   1st Qu.:24.00   Yes:112423   Yes: 10292  \n                         Median :27.00                            \n                         Mean   :28.38                            \n                         3rd Qu.:31.00                            \n                         Max.   :98.00                            \n                                                                  \n HeartDiseaseorAttack PhysActivity Fruits       Veggies      HvyAlcoholConsump\n No :229787           No : 61760   No : 92782   No : 47839   No :239424       \n Yes: 23893           Yes:191920   Yes:160898   Yes:205841   Yes: 14256       \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n AnyHealthcare NoDocbcCost       GenHlth         MentHlth         PhysHlth     \n No : 12417    No :232326   Excellent:45299   Min.   : 0.000   Min.   : 0.000  \n Yes:241263    Yes: 21354   Very Good:89084   1st Qu.: 0.000   1st Qu.: 0.000  \n                            Good     :75646   Median : 0.000   Median : 0.000  \n                            Fair     :31570   Mean   : 3.185   Mean   : 4.242  \n                            Poor     :12081   3rd Qu.: 2.000   3rd Qu.: 3.000  \n                                              Max.   :30.000   Max.   :30.000  \n                                                                               \n DiffWalk         Sex              Age        Education      Income     \n No :211005   Female:141974   9      :33244   1:   174   8      :90385  \n Yes: 42675   Male  :111706   10     :32194   2:  4043   7      :43219  \n                              8      :30832   3:  9478   6      :36470  \n                              7      :26314   4: 62750   5      :25883  \n                              11     :23533   5: 69910   4      :20135  \n                              6      :19819   6:107325   3      :15994  \n                              (Other):87744              (Other):21594  \n\n# Detailed summary statistics for BMI grouped by Diabetes Status\ndiabetes_clean |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    mean_BMI = mean(BMI, na.rm = TRUE),\n    median_BMI = median(BMI, na.rm = TRUE),\n    sd_BMI = sd(BMI, na.rm = TRUE),\n    count = n()\n  )\n\n# A tibble: 2 × 5\n  Diabetes_binary mean_BMI median_BMI sd_BMI  count\n  &lt;fct&gt;              &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;int&gt;\n1 No Diabetes         27.8         27   6.29 218334\n2 Diabetes            31.9         31   7.36  35346\n\n\nClick here for the Modeling Page"
  },
  {
    "objectID": "EDA.html#eda",
    "href": "EDA.html#eda",
    "title": "Project 3",
    "section": "",
    "text": "Click here for the Modeling Page"
  },
  {
    "objectID": "EDA.html#purpose-and-goal",
    "href": "EDA.html#purpose-and-goal",
    "title": "Project 3",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Read the data (assuming the file is in the root directory)\ndiabetes &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nprint(head(diabetes))\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1               0      1        1         1    40      1      0\n2               0      0        0         0    25      1      0\n3               0      1        1         1    28      0      0\n4               0      1        0         1    27      0      0\n5               0      1        1         1    24      0      0\n6               0      1        1         1    25      1      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nConvert variables to factors with meaningful levels\n\ndiabetes_clean &lt;- diabetes |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary, levels = c(0, 1), labels = c(\"No Diabetes\", \"Diabetes\")),\n    HighBP = factor(HighBP, levels = c(0, 1), labels = c(\"No High BP\", \"High BP\")),\n    HighChol = factor(HighChol, levels = c(0, 1), labels = c(\"No High Chol\", \"High Chol\")),\n    CholCheck = factor(CholCheck, levels = c(0, 1), labels = c(\"No Check\", \"Check in 5 yrs\")),\n    Smoker = factor(Smoker, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Stroke = factor(Stroke, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    PhysActivity = factor(PhysActivity, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Fruits = factor(Fruits, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Veggies = factor(Veggies, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    AnyHealthcare = factor(AnyHealthcare, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    NoDocbcCost = factor(NoDocbcCost, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    GenHlth = factor(GenHlth, levels = c(1, 2, 3, 4, 5), \n                     labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    DiffWalk = factor(DiffWalk, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Sex = factor(Sex, levels = c(0, 1), labels = c(\"Female\", \"Male\")),\n    Age = factor(Age),\n    Education = factor(Education),\n    Income = factor(Income)\n  )\n\n# Check for missing values\nmissing_count &lt;- sum(is.na(diabetes_clean))\ncat(\"Total missing values in the dataset:\", missing_count, \"\\n\")\n\nTotal missing values in the dataset: 0 \n\n\nSummary and Statistics\n\nsummary(diabetes_clean)\n\n    Diabetes_binary          HighBP               HighChol     \n No Diabetes:218334   No High BP:144851   No High Chol:146089  \n Diabetes   : 35346   High BP   :108829   High Chol   :107591  \n                                                               \n                                                               \n                                                               \n                                                               \n                                                               \n          CholCheck           BMI        Smoker       Stroke      \n No Check      :  9470   Min.   :12.00   No :141257   No :243388  \n Check in 5 yrs:244210   1st Qu.:24.00   Yes:112423   Yes: 10292  \n                         Median :27.00                            \n                         Mean   :28.38                            \n                         3rd Qu.:31.00                            \n                         Max.   :98.00                            \n                                                                  \n HeartDiseaseorAttack PhysActivity Fruits       Veggies      HvyAlcoholConsump\n No :229787           No : 61760   No : 92782   No : 47839   No :239424       \n Yes: 23893           Yes:191920   Yes:160898   Yes:205841   Yes: 14256       \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n AnyHealthcare NoDocbcCost       GenHlth         MentHlth         PhysHlth     \n No : 12417    No :232326   Excellent:45299   Min.   : 0.000   Min.   : 0.000  \n Yes:241263    Yes: 21354   Very Good:89084   1st Qu.: 0.000   1st Qu.: 0.000  \n                            Good     :75646   Median : 0.000   Median : 0.000  \n                            Fair     :31570   Mean   : 3.185   Mean   : 4.242  \n                            Poor     :12081   3rd Qu.: 2.000   3rd Qu.: 3.000  \n                                              Max.   :30.000   Max.   :30.000  \n                                                                               \n DiffWalk         Sex              Age        Education      Income     \n No :211005   Female:141974   9      :33244   1:   174   8      :90385  \n Yes: 42675   Male  :111706   10     :32194   2:  4043   7      :43219  \n                              8      :30832   3:  9478   6      :36470  \n                              7      :26314   4: 62750   5      :25883  \n                              11     :23533   5: 69910   4      :20135  \n                              6      :19819   6:107325   3      :15994  \n                              (Other):87744              (Other):21594  \n\n# Detailed summary statistics for BMI grouped by Diabetes Status\ndiabetes_clean |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    mean_BMI = mean(BMI, na.rm = TRUE),\n    median_BMI = median(BMI, na.rm = TRUE),\n    sd_BMI = sd(BMI, na.rm = TRUE),\n    count = n()\n  )\n\n# A tibble: 2 × 5\n  Diabetes_binary mean_BMI median_BMI sd_BMI  count\n  &lt;fct&gt;              &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;int&gt;\n1 No Diabetes         27.8         27   6.29 218334\n2 Diabetes            31.9         31   7.36  35346\n\n\nClick here for the Modeling Page"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Project 3",
    "section": "",
    "text": "In this project, we analyze the Diabetes Health Indicators Dataset, which is derived from the BRFSS 2015 data. This dataset includes health-related responses from individuals, focusing on chronic conditions and lifestyle factors.\n\n\nThe dataset contains 21 variables and 253,680 observations.\nWe will focus our investigation on specific variables that are likely to be strong predictors of diabetes. The key variables in our analysis include:\n\nDiabetes_binary (Response): The target variable indicating the presence of diabetes (0 = No Diabetes, 1 = Diabetes or Prediabetes).\nBMI: Body Mass Index, a key indicator of obesity.\nHighBP: Whether the individual has high blood pressure.\nAge: 13-level age category (ranging from 18-24 up to 80+).\nGenHlth: Self-reported general health on a scale of 1 (Excellent) to 5 (Poor).\n\n\n\n\n\nThe purpose of this Exploratory Data Analysis (EDA) : examine the distributions of these variables and investigate the relationships between the health indicators and the diabetes status. By visualizing these associations, we aim to verify which factors are most strongly correlated with diabetes.\nThe ultimate goal of this project : use these insights to build and compare predictive models—specifically a Classification Tree and a Random Forest—to accurately classify whether an individual has diabetes based on their health profile."
  },
  {
    "objectID": "index.html#purpose-and-goal",
    "href": "index.html#purpose-and-goal",
    "title": "Project 3",
    "section": "",
    "text": "The purpose of this Exploratory Data Analysis (EDA) : examine the distributions of these variables and investigate the relationships between the health indicators and the diabetes status. By visualizing these associations, we aim to verify which factors are most strongly correlated with diabetes.\nThe ultimate goal of this project : use these insights to build and compare predictive models—specifically a Classification Tree and a Random Forest—to accurately classify whether an individual has diabetes based on their health profile."
  },
  {
    "objectID": "index.html#convert-variables-to-factors-with-meaningful-levels",
    "href": "index.html#convert-variables-to-factors-with-meaningful-levels",
    "title": "Project 3",
    "section": "2.1. Convert variables to factors with meaningful levels",
    "text": "2.1. Convert variables to factors with meaningful levels\n\ndiabetes_clean &lt;- diabetes |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary, levels = c(0, 1), labels = c(\"No Diabetes\", \"Diabetes\")),\n    HighBP = factor(HighBP, levels = c(0, 1), labels = c(\"No High BP\", \"High BP\")),\n    HighChol = factor(HighChol, levels = c(0, 1), labels = c(\"No High Chol\", \"High Chol\")),\n    CholCheck = factor(CholCheck, levels = c(0, 1), labels = c(\"No Check\", \"Check in 5 yrs\")),\n    Smoker = factor(Smoker, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Stroke = factor(Stroke, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    PhysActivity = factor(PhysActivity, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Fruits = factor(Fruits, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Veggies = factor(Veggies, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    AnyHealthcare = factor(AnyHealthcare, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    NoDocbcCost = factor(NoDocbcCost, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    GenHlth = factor(GenHlth, levels = c(1, 2, 3, 4, 5), \n                     labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    DiffWalk = factor(DiffWalk, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Sex = factor(Sex, levels = c(0, 1), labels = c(\"Female\", \"Male\")),\n    Age = factor(Age),\n    Education = factor(Education),\n    Income = factor(Income)\n  )\n\n# Check for missing values\nmissing_count &lt;- sum(is.na(diabetes_clean))\ncat(\"Total missing values in the dataset:\", missing_count, \"\\n\")\n\nTotal missing values in the dataset: 0"
  },
  {
    "objectID": "index.html#summary-and-statistics",
    "href": "index.html#summary-and-statistics",
    "title": "Project 3",
    "section": "2.2. Summary and Statistics",
    "text": "2.2. Summary and Statistics\nWe use summary() to get a broad overview of the data distributions, and summarize() to examine specific relationships with the response variable.\n\nsummary(diabetes_clean)\n\n    Diabetes_binary          HighBP               HighChol     \n No Diabetes:218334   No High BP:144851   No High Chol:146089  \n Diabetes   : 35346   High BP   :108829   High Chol   :107591  \n                                                               \n                                                               \n                                                               \n                                                               \n                                                               \n          CholCheck           BMI        Smoker       Stroke      \n No Check      :  9470   Min.   :12.00   No :141257   No :243388  \n Check in 5 yrs:244210   1st Qu.:24.00   Yes:112423   Yes: 10292  \n                         Median :27.00                            \n                         Mean   :28.38                            \n                         3rd Qu.:31.00                            \n                         Max.   :98.00                            \n                                                                  \n HeartDiseaseorAttack PhysActivity Fruits       Veggies      HvyAlcoholConsump\n No :229787           No : 61760   No : 92782   No : 47839   No :239424       \n Yes: 23893           Yes:191920   Yes:160898   Yes:205841   Yes: 14256       \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n AnyHealthcare NoDocbcCost       GenHlth         MentHlth         PhysHlth     \n No : 12417    No :232326   Excellent:45299   Min.   : 0.000   Min.   : 0.000  \n Yes:241263    Yes: 21354   Very Good:89084   1st Qu.: 0.000   1st Qu.: 0.000  \n                            Good     :75646   Median : 0.000   Median : 0.000  \n                            Fair     :31570   Mean   : 3.185   Mean   : 4.242  \n                            Poor     :12081   3rd Qu.: 2.000   3rd Qu.: 3.000  \n                                              Max.   :30.000   Max.   :30.000  \n                                                                               \n DiffWalk         Sex              Age        Education      Income     \n No :211005   Female:141974   9      :33244   1:   174   8      :90385  \n Yes: 42675   Male  :111706   10     :32194   2:  4043   7      :43219  \n                              8      :30832   3:  9478   6      :36470  \n                              7      :26314   4: 62750   5      :25883  \n                              11     :23533   5: 69910   4      :20135  \n                              6      :19819   6:107325   3      :15994  \n                              (Other):87744              (Other):21594  \n\n# Detailed summary statistics for BMI grouped by Diabetes Status\ndiabetes_clean |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    mean_BMI = mean(BMI, na.rm = TRUE),\n    median_BMI = median(BMI, na.rm = TRUE),\n    sd_BMI = sd(BMI, na.rm = TRUE),\n    count = n()\n  )\n\n# A tibble: 2 × 5\n  Diabetes_binary mean_BMI median_BMI sd_BMI  count\n  &lt;fct&gt;              &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;int&gt;\n1 No Diabetes         27.8         27   6.29 218334\n2 Diabetes            31.9         31   7.36  35346\n\n\n\nBMI Differences: The grouped summary table explicitly highlights a relationship between BMI and Diabetes. The mean BMI for the “Diabetes” group (approx. 31.9) is noticeably higher than the “No Diabetes” group (approx. 27.8). This suggests that BMI is likely a strong predictor."
  },
  {
    "objectID": "index.html#the-response-variable-diabetes-status",
    "href": "index.html#the-response-variable-diabetes-status",
    "title": "Project 3",
    "section": "3.1. The Response Variable: Diabetes Status",
    "text": "3.1. The Response Variable: Diabetes Status\n\nggplot(diabetes_clean, aes(x = Diabetes_binary, fill = Diabetes_binary)) +\n  geom_bar() +\n  labs(title = \"Distribution of Diabetes Status\", x = \"Status\", y = \"Count\")\n\n\n\n\n\n\n\n\nThis bar chart visually confirms the class imbalance identified in the summary statistics. The number of healthy individuals vastly outnumbers those with diabetes."
  },
  {
    "objectID": "index.html#diabetes-vs.-bmi",
    "href": "index.html#diabetes-vs.-bmi",
    "title": "Project 3",
    "section": "3.2. Diabetes vs. BMI",
    "text": "3.2. Diabetes vs. BMI\n\nggplot(diabetes_clean, aes(x = Diabetes_binary, y = BMI, fill = Diabetes_binary)) +\n  geom_boxplot() +\n  labs(title = \"BMI Distribution by Diabetes Status\", x = \"Diabetes Status\", y = \"BMI\")\n\n\n\n\n\n\n\n\nThe boxplot illustrates a clear positive correlation between BMI and diabetes. The median BMI for the “Diabetes” group is visibly higher than that of the “No Diabetes” group. Furthermore, the entire interquartile range (the box) is shifted upwards for the diabetes group. This strongly suggests that as BMI increases, the likelihood of having diabetes also increases."
  },
  {
    "objectID": "index.html#diabetes-vs.-high-blood-pressure",
    "href": "index.html#diabetes-vs.-high-blood-pressure",
    "title": "Project 3",
    "section": "3.3. Diabetes vs. High Blood Pressure",
    "text": "3.3. Diabetes vs. High Blood Pressure\n\nggplot(diabetes_clean, aes(x = HighBP, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Diabetes Count by High Blood Pressure Status\", \n       x = \"High Blood Pressure\", \n       y = \"Count\")\n\n\n\n\n\n\n\n\nThis plot illustrates a clear positive correlation between BMI and High Blood Pressure. In the “No High BP” group, the proportion of people with diabetes is very small. However, in the “High BP” group, the count of people with diabetes is significant. This indicates that High Blood Pressure is a significant risk factor for diabetes."
  },
  {
    "objectID": "index.html#diabetes-vs.-age",
    "href": "index.html#diabetes-vs.-age",
    "title": "Project 3",
    "section": "3.4. Diabetes vs. Age",
    "text": "3.4. Diabetes vs. Age\n\nggplot(diabetes_clean, aes(x = Age, fill = Diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Proportion of Diabetes by Age Group\", \n       subtitle = \"Age groups coded 1 (18-24) to 13 (80+)\",\n       x = \"Age Group Level\", \n       y = \"Proportion\")\n\n\n\n\n\n\n\n\nThe stacked bar chart shows a clear linear trend: as age increases (moving from group 1 to group 13), the proportion of individuals with diabetes (the blue section) steadily increases. The risk appears to peak around age groups 10 through 12. This suggests that age is a significant factor in diabetes prevalence, with older individuals being at a higher risk."
  },
  {
    "objectID": "index.html#bmi-by-diabetes-status-faceted-by-general-health",
    "href": "index.html#bmi-by-diabetes-status-faceted-by-general-health",
    "title": "Project 3",
    "section": "3.5. BMI by Diabetes Status Faceted by General Health",
    "text": "3.5. BMI by Diabetes Status Faceted by General Health\n\nggplot(diabetes_clean, aes(x = BMI, fill = Diabetes_binary)) +\n  geom_histogram(binwidth = 1, alpha = 0.5, position = \"identity\") +\n  facet_wrap(~ GenHlth) +\n  labs(title = \"BMI Distribution by Diabetes Status across General Health Ratings\",\n       x = \"BMI\",\n       y = \"Count\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nThis faceted plot allows us to see if the BMI-Diabetes relationship holds true regardless of self-reported general health.\nAcross almost all health ratings (from “Excellent” to “Poor”), the distribution of BMI for the Diabetes group (blue) is shifted to the right compared to the No Diabetes group (red).\nIt also shows that the “Poor” and “Fair” health categories have a larger overlap of diabetes cases compared to the “Excellent” category, suggesting that poor general health is strongly linked to both higher BMI and diabetes."
  },
  {
    "objectID": "index.html#data-and-variables",
    "href": "index.html#data-and-variables",
    "title": "Project 3",
    "section": "",
    "text": "The dataset contains 21 variables and 253,680 observations.\nWe will focus our investigation on specific variables that are likely to be strong predictors of diabetes. The key variables in our analysis include:\n\nDiabetes_binary (Response): The target variable indicating the presence of diabetes (0 = No Diabetes, 1 = Diabetes or Prediabetes).\nBMI: Body Mass Index, a key indicator of obesity.\nHighBP: Whether the individual has high blood pressure.\nAge: 13-level age category (ranging from 18-24 up to 80+).\nGenHlth: Self-reported general health on a scale of 1 (Excellent) to 5 (Poor)."
  },
  {
    "objectID": "modeling.html",
    "href": "modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "In this section, we will build predictive models to classify whether an individual has diabetes (Diabetes_binary) based on various health indicators.\nWe will explore two types of models:\nClassification Tree: A decision tree model that splits data into nodes to make predictions.\nRandom Forest: An ensemble method that aggregates predictions from multiple decision trees to improve accuracy and reduce overfitting.\nWe will use the log-loss metric to evaluate model performance and 5-fold Cross-Validation on the training set to tune hyperparameters. Finally, we will compare the best models from each category on the test set to select the final winner."
  },
  {
    "objectID": "modeling.html#data-splitting",
    "href": "modeling.html#data-splitting",
    "title": "Modeling",
    "section": "2.1. Data Splitting",
    "text": "2.1. Data Splitting\nWe split the data into a training set (70%) and a test set (30%). We set a seed to ensure reproducibility.\n\nset.seed(123)\n\n# Stratified split to maintain class balance\ndata_split &lt;- initial_split(diabetes_clean, prop = 0.70, strata = Diabetes_binary)\ntrain_data &lt;- training(data_split)\ntest_data  &lt;- testing(data_split)\n\n# Verify the split\nnrow(train_data)\n\n[1] 177575\n\nnrow(test_data)\n\n[1] 76105"
  },
  {
    "objectID": "modeling.html#cross-validation-folds",
    "href": "modeling.html#cross-validation-folds",
    "title": "Modeling",
    "section": "2.2. Cross-Validation Folds",
    "text": "2.2. Cross-Validation Folds\nWe will use 5-fold cross-validation on the training data to tune our model parameters.\n\ncv_folds &lt;- vfold_cv(train_data, v = 5, strata = Diabetes_binary)\n\n# Define the metric set: Log Loss\nmetrics_eval &lt;- metric_set(mn_log_loss)"
  },
  {
    "objectID": "modeling.html#introduction-to-classification-trees",
    "href": "modeling.html#introduction-to-classification-trees",
    "title": "Modeling",
    "section": "3.1. Introduction to Classification Trees",
    "text": "3.1. Introduction to Classification Trees\nA Classification Tree is a supervised learning algorithm that predicts the target variable by learning decision rules inferred from the data features. It works by recursively splitting the data into subsets based on the most significant attribute at each step.\nWe will tune the cost complexity parameter and tree depth to find the optimal tree size and prevent overfitting."
  },
  {
    "objectID": "modeling.html#model-specification-and-workflow",
    "href": "modeling.html#model-specification-and-workflow",
    "title": "Modeling",
    "section": "3.2. Model Specification and Workflow",
    "text": "3.2. Model Specification and Workflow\n\n# 1. Recipe\ntree_rec &lt;- recipe(Diabetes_binary ~ BMI + HighBP + HighChol + GenHlth + Age + PhysActivity + DiffWalk + HeartDiseaseorAttack, data = train_data)\n\nWe set cost_complexity and tree_depth to ‘tune()’ so we can optimize them later.\n\n# 2. Model Specification\ntree_spec &lt;- decision_tree(\n  cost_complexity = tune(),\n  tree_depth = tune()\n) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n# 3. Workflow\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(tree_rec) |&gt;\n  add_model(tree_spec)\n\n# 4. Grid for Tuning\ntree_grid &lt;- grid_regular(cost_complexity(), tree_depth(), levels = 5)"
  },
  {
    "objectID": "modeling.html#tuning-and-selection",
    "href": "modeling.html#tuning-and-selection",
    "title": "Modeling",
    "section": "3.3. Tuning and selection",
    "text": "3.3. Tuning and selection\nRun the workflow on the cross-validation folds using the grid of parameters\n\n# Tune the model\ntree_fits &lt;- tree_wkf |&gt;\n  tune_grid(\n    resamples = cv_folds,\n    grid = tree_grid,\n    metrics = metrics_eval\n  )\n\n\n# Collect metrics\ntree_fits |&gt;\n  collect_metrics()\n\n# A tibble: 25 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001          1 mn_log_loss binary     0.404     5 9.73e-6 pre0_m…\n 2    0.0000000001          4 mn_log_loss binary     0.394     5 9.45e-3 pre0_m…\n 3    0.0000000001          8 mn_log_loss binary     0.332     5 1.91e-3 pre0_m…\n 4    0.0000000001         11 mn_log_loss binary     0.328     5 1.19e-3 pre0_m…\n 5    0.0000000001         15 mn_log_loss binary     0.336     5 1.66e-3 pre0_m…\n 6    0.0000000178          1 mn_log_loss binary     0.404     5 9.73e-6 pre0_m…\n 7    0.0000000178          4 mn_log_loss binary     0.394     5 9.45e-3 pre0_m…\n 8    0.0000000178          8 mn_log_loss binary     0.332     5 1.91e-3 pre0_m…\n 9    0.0000000178         11 mn_log_loss binary     0.328     5 1.19e-3 pre0_m…\n10    0.0000000178         15 mn_log_loss binary     0.336     5 1.66e-3 pre0_m…\n# ℹ 15 more rows\n\n\nWe select the best parameter based on log_loss.\n\nbest_tree &lt;- select_best(tree_fits, metric = \"mn_log_loss\")\nbest_tree\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config         \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;           \n1    0.0000000001         11 pre0_mod04_post0\n\n\nWe finalize the workflow with the best parameters.\n\n# \ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(best_tree)\n\nWe visualize the tuning results using plot Cost Complexity vs. Log Loss, grouped by Tree Depth.\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  mutate(tree_depth = factor(tree_depth)) |&gt;\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0) +\n  labs(title = \"Classification Tree Tuning Results\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nWe train the finalized model on the full training set and evaluates it on the test set.\n\ntree_final_fit &lt;- tree_final_wkf |&gt;\n  last_fit(data_split)\ntree_final_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                 id            .metrics .notes   .predictions .workflow \n  &lt;list&gt;                 &lt;chr&gt;         &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [177575/76105]&gt; train/test s… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\n\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 3 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 accuracy    binary         0.863 pre0_mod0_post0\n2 roc_auc     binary         0.803 pre0_mod0_post0\n3 brier_class binary         0.100 pre0_mod0_post0\n\n\nWe extract the actual model object for inspection.\n\ntree_final_model &lt;- extract_workflow(tree_final_fit) \ntree_final_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 177575 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 177575 24742 No Diabetes (0.86066732 0.13933268)  \n     2) HighBP=No High BP 101541  6156 No Diabetes (0.93937424 0.06062576)  \n       4) GenHlth=Excellent,Very Good 65580  1755 No Diabetes (0.97323879 0.02676121) *\n       5) GenHlth=Good,Fair,Poor 35961  4401 No Diabetes (0.87761742 0.12238258)  \n        10) HighChol=No High Chol 23063  2054 No Diabetes (0.91093960 0.08906040)  \n          20) Age=1,2,3,4,5,6,7,8 15458   936 No Diabetes (0.93944883 0.06055117) *\n          21) Age=9,10,11,12,13 7605  1118 No Diabetes (0.85299145 0.14700855)  \n            42) BMI&lt; 28.5 5071   532 No Diabetes (0.89508973 0.10491027)  \n              84) BMI&lt; 23.5 2024   134 No Diabetes (0.93379447 0.06620553) *\n              85) BMI&gt;=23.5 3047   398 No Diabetes (0.86937972 0.13062028)  \n               170) HeartDiseaseorAttack=No 2646   311 No Diabetes (0.88246410 0.11753590) *\n               171) HeartDiseaseorAttack=Yes 401    87 No Diabetes (0.78304239 0.21695761)  \n                 342) BMI&lt; 25.5 160    22 No Diabetes (0.86250000 0.13750000) *\n                 343) BMI&gt;=25.5 241    65 No Diabetes (0.73029046 0.26970954)  \n                   686) DiffWalk=No 144    32 No Diabetes (0.77777778 0.22222222) *\n                   687) DiffWalk=Yes 97    33 No Diabetes (0.65979381 0.34020619)  \n                    1374) Age=9,11,12,13 83    24 No Diabetes (0.71084337 0.28915663) *\n                    1375) Age=10 14     5 Diabetes (0.35714286 0.64285714) *\n            43) BMI&gt;=28.5 2534   586 No Diabetes (0.76874507 0.23125493)  \n              86) GenHlth=Good 1649   296 No Diabetes (0.82049727 0.17950273)  \n               172) HeartDiseaseorAttack=No 1482   243 No Diabetes (0.83603239 0.16396761) *\n               173) HeartDiseaseorAttack=Yes 167    53 No Diabetes (0.68263473 0.31736527)  \n                 346) Age=13 33     7 No Diabetes (0.78787879 0.21212121) *\n                 347) Age=9,10,11,12 134    46 No Diabetes (0.65671642 0.34328358)  \n                   694) BMI&lt; 29.5 23     5 No Diabetes (0.78260870 0.21739130) *\n                   695) BMI&gt;=29.5 111    41 No Diabetes (0.63063063 0.36936937)  \n                    1390) BMI&lt; 36.5 90    31 No Diabetes (0.65555556 0.34444444) *\n                    1391) BMI&gt;=36.5 21    10 No Diabetes (0.52380952 0.47619048)  \n                      2782) PhysActivity=Yes 13     4 No Diabetes (0.69230769 0.30769231) *\n                      2783) PhysActivity=No 8     2 Diabetes (0.25000000 0.75000000) *\n              87) GenHlth=Fair,Poor 885   290 No Diabetes (0.67231638 0.32768362)  \n               174) HeartDiseaseorAttack=No 698   203 No Diabetes (0.70916905 0.29083095)  \n                 348) BMI&lt; 33.5 405    99 No Diabetes (0.75555556 0.24444444)  \n                   696) Age=9,10,13 284    60 No Diabetes (0.78873239 0.21126761) *\n                   697) Age=11,12 121    39 No Diabetes (0.67768595 0.32231405)  \n                    1394) BMI&lt; 31.5 83    21 No Diabetes (0.74698795 0.25301205) *\n                    1395) BMI&gt;=31.5 38    18 No Diabetes (0.52631579 0.47368421)  \n                      2790) GenHlth=Fair 30    13 No Diabetes (0.56666667 0.43333333) *\n                      2791) GenHlth=Poor 8     3 Diabetes (0.37500000 0.62500000) *\n                 349) BMI&gt;=33.5 293   104 No Diabetes (0.64505119 0.35494881)  \n                   698) Age=9,10,12 223    71 No Diabetes (0.68161435 0.31838565)  \n                    1396) BMI&lt; 54.5 215    66 No Diabetes (0.69302326 0.30697674) *\n                    1397) BMI&gt;=54.5 8     3 Diabetes (0.37500000 0.62500000) *\n                   699) Age=11,13 70    33 No Diabetes (0.52857143 0.47142857)  \n                    1398) GenHlth=Fair 52    23 No Diabetes (0.55769231 0.44230769) *\n\n...\nand 502 more lines.\n\n\nWe visualizing the Decision Tree.\n\ntree_final_model |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = FALSE)\n\nWarning: labs do not fit even at cex 0.15, there may be some overplotting"
  },
  {
    "objectID": "modeling.html#introduction-to-random-forest",
    "href": "modeling.html#introduction-to-random-forest",
    "title": "Modeling",
    "section": "4.1. Introduction to Random Forest",
    "text": "4.1. Introduction to Random Forest\nA Random Forest is an ensemble learning method that constructs a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees (mode).\nRandom forests generally outperform single decision trees because they correct for the habit of decision trees to overfit to their training set. We will tune mtry (number of variables randomly sampled at each split) and min_n (minimum number of data points in a node)."
  },
  {
    "objectID": "modeling.html#model-specification-and-workflow-1",
    "href": "modeling.html#model-specification-and-workflow-1",
    "title": "Modeling",
    "section": "4.2. Model Specification and Workflow",
    "text": "4.2. Model Specification and Workflow\n\n# 1. Recipe (We can reuse the same predictors)\nrf_rec &lt;- tree_rec\n\n# 2. Model Specification\nrf_spec &lt;- rand_forest(\n  mtry = tune(),\n  min_n = tune(),\n  trees = 100 # Kept low for compilation speed, increase for production\n) |&gt;\n  set_engine(\"ranger\", importance = \"impurity\") |&gt;\n  set_mode(\"classification\")\n\n# 3. Workflow\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(rf_rec) |&gt;\n  add_model(rf_spec)\n\n# 4. Grid for Tuning\n# mtry range depends on number of predictors (we have 8 predictors in recipe)\nrf_grid &lt;- grid_regular(\n  mtry(range = c(2, 7)),\n  min_n(),\n  levels = 3\n)"
  },
  {
    "objectID": "modeling.html#tuning-and-selection-1",
    "href": "modeling.html#tuning-and-selection-1",
    "title": "Modeling",
    "section": "4.3. Tuning and selection",
    "text": "4.3. Tuning and selection\n\n# Tune the model\nrf_fits &lt;- rf_wkf |&gt;\n  tune_grid(\n    resamples = cv_folds,\n    grid = rf_grid,\n    metrics = metrics_eval\n  )\n\n\n# Collect metrics\nrf_fits |&gt;\n  collect_metrics()\n\n# A tibble: 9 × 8\n   mtry min_n .metric     .estimator  mean     n  std_err .config        \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1     2     2 mn_log_loss binary     0.319     5 0.000711 pre0_mod1_post0\n2     2    21 mn_log_loss binary     0.319     5 0.000898 pre0_mod2_post0\n3     2    40 mn_log_loss binary     0.319     5 0.000856 pre0_mod3_post0\n4     4     2 mn_log_loss binary     0.330     5 0.00131  pre0_mod4_post0\n5     4    21 mn_log_loss binary     0.324     5 0.00118  pre0_mod5_post0\n6     4    40 mn_log_loss binary     0.321     5 0.00112  pre0_mod6_post0\n7     7     2 mn_log_loss binary     0.434     5 0.00338  pre0_mod7_post0\n8     7    21 mn_log_loss binary     0.357     5 0.00214  pre0_mod8_post0\n9     7    40 mn_log_loss binary     0.344     5 0.00162  pre0_mod9_post0\n\n\n\n# Select the best parameter based on log_loss\nbest_rf &lt;- select_best(rf_fits, metric = \"mn_log_loss\")\nbest_rf\n\n# A tibble: 1 × 3\n   mtry min_n .config        \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;          \n1     2    40 pre0_mod3_post0\n\n# Finalize the workflow with the best parameters\nrf_final_wkf &lt;- rf_wkf |&gt;\n  finalize_workflow(best_rf)\n\n\n# Visualize the tuning results\nrf_fits |&gt;\n  collect_metrics() |&gt;\n  mutate(min_n = factor(min_n)) |&gt;\n  ggplot(aes(mtry, mean, color = min_n)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0) +\n  labs(title = \"Random Forest Tuning Results\")\n\n\n\n\n\n\n\n\n\nrf_final_fit &lt;- rf_final_wkf |&gt;\n  last_fit(data_split, metrics = metrics_eval)\nrf_final_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                 id            .metrics .notes   .predictions .workflow \n  &lt;list&gt;                 &lt;chr&gt;         &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [177575/76105]&gt; train/test s… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\n\nrf_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 mn_log_loss binary         0.320 pre0_mod0_post0\n\n\n\nrf_final_model &lt;- extract_workflow(rf_final_fit) \nrf_final_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~2L,      x), num.trees = ~100, min.node.size = min_rows(~40L, x),      importance = ~\"impurity\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  100 \nSample size:                      177575 \nNumber of independent variables:  8 \nMtry:                             2 \nTarget node size:                 40 \nVariable importance mode:         impurity \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.09838308 \n\n\n\n# Visualization of the best Random Forest (Variable Importance)\nrf_final_model |&gt;\n  extract_fit_parsnip() |&gt;\n  vip::vip() +\n  labs(title = \"Random Forest Variable Importance\")"
  }
]